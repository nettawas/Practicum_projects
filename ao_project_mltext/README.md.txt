# Классификация токсичных комментариев для «Викишоп»

Интернет-магазин «Викишоп» запускает сервис, где пользователи могут редактировать и комментировать описания товаров. Чтобы защитить платформу от токсичного поведения, была поставлена задача — создать модель, автоматически определяющую токсичные комментарии и отправляющую их на модерацию.

## Описание проекта

Построена модель бинарной классификации, определяющая, является ли пользовательский комментарий токсичным. Основная цель — достичь значения метрики F1 не ниже 0.75. В рамках проекта были проведены предобработка текста, обучение и сравнение нескольких моделей машинного обучения.

## Данные

Исходный файл: `toxic_comments.csv`  
- `text` — текст комментария;  
- `toxic` — целевой признак: 1 — токсичный комментарий, 0 — нормальный.

Разметка подготовлена заранее. В качестве обучающей и тестовой выборки использовано 20% данных для ускорения экспериментов.

## Методы и модели

- Очистка текста, токенизация, векторизация с помощью CountVectorizer и TF-IDF;
- Обучение различных моделей: Logistic Regression, Random Forest, Naive Bayes, BERT (экспериментально);
- Основная модель: `LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)`;
- Использовалась балансировка классов и кросс-валидация;
- Подбор гиперпараметров с помощью GridSearchCV (сокращённая сетка).

## Метрика качества

- Целевая метрика: **F1-score ≥ 0.75**;
- На тестовой выборке достигнуто: **F1 ≈ 0.75**;
- Использована уменьшенная выборка для ускорения экспериментов (20% от полного объёма данных).

## Результат

Модель на базе логистической регрессии успешно справляется с задачей классификации токсичных комментариев, демонстрируя стабильное значение F1 ≥ 0.75. Полученные результаты позволяют использовать модель как основу для системы автоматической модерации на платформе «Викишоп».
